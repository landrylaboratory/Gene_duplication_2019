{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather PDB info\n",
    "\n",
    "This script will create a table summarizing the information I can get from the PDB files. Such a final table will have the following columns:\n",
    "\n",
    "- P1_ID\n",
    "- P2_ID\n",
    "- Duplication type\n",
    "- Monomer_P1 (the ID of a PDB structure that shows the P1 monomer or NA if there is none in my set)\n",
    "- Monomer_P2 (the ID of a PDB structure that shows the P2 monomer or NA if there is none in my set)\n",
    "- HM_P1 (the ID of a PDB structure whose biological assembly is not a monomer AND has at least two copies of P1)\n",
    "- HM_P2 (the ID of a PDB structure whose biological assembly is not a monomer AND has at least two copies of P2)\n",
    "- HET (the ID of a PDB structure whose biological assembly is not a monomer AND has at least one copy of each of P1 and P2)\n",
    "- P1_unspecific (1 if P1 is in the list of structures with unspecific interactions in Tarassov's data, 0 otherwise)\n",
    "- P2_unspecific (1 if P2 is in the list of structures with unspecific interactions in Tarassov's data, 0 otherwise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall plan\n",
    "\n",
    "- Write a script to extract the following from each of the PDB files I could download\n",
    "    - REMARK 350: Number of subunits in assembly 1 (monomeric, dimeric, etc)\n",
    "    - Resolution (I can optionally use this as a filter, say make sure all the structures have a resolution of 3 Ã… or better)\n",
    "- Load table with data about the files I could not download\n",
    "- Load table with alignment data for all SSD, WGD hits\n",
    "- Apply filters\n",
    "- Match the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import csv\n",
    "import glob\n",
    "import re\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Working with the information from the PDB files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_text_2_numbers = {\n",
    "     'MONOMERIC': 1, \n",
    "     'DIMERIC': 2,\n",
    "     'TRIMERIC': 3,\n",
    "     'TETRAMERIC': 4,\n",
    "     'PENTAMERIC': 5,\n",
    "     'HEXAMERIC': 6,\n",
    "     'HEPTAMERIC': 7,\n",
    "     'OCTAMERIC': 8,\n",
    "     'NONAMERIC': 9,\n",
    "     'DECAMERIC': 10,\n",
    "     'UNDECAMERIC': 11,\n",
    "     'DODECAMERIC': 12,\n",
    "     'TRIDECAMERIC': 13,\n",
    "     'TETRADECAMERIC': 14,\n",
    "     'PENTADECAMERIC': 15,\n",
    "     'HEXADECAMERIC': 16,\n",
    "     'HEPTADECAMERIC': 17,\n",
    "     'OCTADECAMERIC': 18,\n",
    "     'NONADECAMERIC': 19,\n",
    "     'EICOSAMERIC': 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_pdb_data(pdb_file, dict_text_2_numbers):\n",
    "    '''This function will receive the path to a PDB file and extract its information as a list with:\n",
    "    - The PDB ID\n",
    "    - The biological assembly assigned by the authors\n",
    "    - The total number of subunits in that assembly\n",
    "    - The structure's resolution, if applicable\n",
    "    - A dictionary containing the IDs of those chains and how many times they appear in the assembly\n",
    "    '''\n",
    "    handle = open(pdb_file, 'r')\n",
    "    pdb_id = pdb_file.split('/')[-1][0:4]\n",
    "    resolution = 'NA'\n",
    "    quit_bool = False\n",
    "    \n",
    "    # This dictionary will tell me how many times each chain is found in the selected biological assembly\n",
    "    chains_dict = OrderedDict()\n",
    "    \n",
    "    # Loop through the lines to look for REMARK 350\n",
    "    for line in handle:\n",
    "        if line.startswith('EXPDTA'):\n",
    "            # I will split the line on the experimental data with at least two spaces\n",
    "            expdata = re.split(' [ ]+', line)[1]    \n",
    "        if line.startswith('REMARK   2 RESOLUTION.'):\n",
    "            # Extract the resolution\n",
    "            res_match = re.search('([0-9\\.]+)[ ]+ANGSTROM', line)\n",
    "            if res_match:\n",
    "                resolution = res_match.group(1)\n",
    "        if line.startswith('REMARK 350'):\n",
    "            # Then, I want to start reading.\n",
    "            # I want to read what the biological assembly is, and then check what the one determined by the authors is\n",
    "            # I will stop reading once I find one that was determined by the authors\n",
    "            match_assembly = re.search('BIOMOLECULE:[ ]+([0-9]+)', line)\n",
    "            if match_assembly:   \n",
    "                if quit_bool:\n",
    "                    # If I have all the data for the assembly selected by the authors and I find a new assembly, \n",
    "                    # I will stop and just quit\n",
    "                    subunit_number = dict_text_2_numbers.get(subunit_number, subunit_number)\n",
    "                    return [pdb_id, bio_assembly, subunit_number, expdata, resolution, chains_dict]\n",
    "                else:\n",
    "                    # Otherwise, I read the next one because I still have not found the one assigned by the authors\n",
    "                    bio_assembly = int(match_assembly.group(1))\n",
    "            \n",
    "            # Now that we know with which biological assembly we are working, we can check if it is the one determined\n",
    "            # by the authors.\n",
    "            match_author = re.search('AUTHOR DETERMINED BIOLOGICAL UNIT: ([a-zA-Z0-9]+)', line)\n",
    "            if match_author:\n",
    "                subunit_number = match_author.group(1)\n",
    "                \n",
    "                # This means that we have now found the assembly determined by the authors\n",
    "                quit_bool = True\n",
    "            \n",
    "            # I will need to check which chains are in this biological assembly\n",
    "            match_chains_1 = re.search('APPLY THE FOLLOWING TO CHAINS: ([a-zA-Z0-9, ]+)', line)\n",
    "            if match_chains_1:\n",
    "                chains_assembly = match_chains_1.group(1).strip()\n",
    "            \n",
    "            # Sometimes the chains don't fit in a single line (example: 2ja7)\n",
    "            match_chains_2 = re.search('AND CHAINS: ([a-zA-Z0-9, ]+)', line)\n",
    "            if match_chains_2:\n",
    "                chains_assembly = chains_assembly + ' ' + match_chains_2.group(1).strip()\n",
    "            \n",
    "            # Sometimes a single chain is used to obtain two chains (example: 3qps)\n",
    "            # I need to look for the BIOMT line\n",
    "            match_biomt = re.search('BIOMT\\d   (\\d)', line)\n",
    "            if match_biomt:\n",
    "                all_chains = chains_assembly.split(', ')\n",
    "                for chain in all_chains:\n",
    "                    chains_dict[chain] = int(match_biomt.group(1))\n",
    "            \n",
    "            \n",
    "    # If I reach the end of the file without having an author determined unit, I will consider it to be monomeric\n",
    "    # This is something I can check easily as to see if there are exceptions. \n",
    "    # An example of a PDB file that does not state the authors' preference is 1a1d, but it\n",
    "    # was obtained with solution NMR\n",
    "    if quit_bool:\n",
    "        # Make sure I convert the assembly types from text to numbers\n",
    "        subunit_number = dict_text_2_numbers.get(subunit_number, subunit_number)\n",
    "        return [pdb_id, bio_assembly, subunit_number, expdata, resolution, chains_dict]\n",
    "    else:\n",
    "        return [pdb_id, 1, 1, expdata, resolution, chains_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1a1d', 1, 1, 'SOLUTION NMR', 'NA', OrderedDict()]\n",
      "['2ja7', 1, 15, 'X-RAY DIFFRACTION', '3.8', OrderedDict([('A', 1), ('B', 1), ('C', 1), ('D', 1), ('E', 1), ('F', 1), ('G', 1), ('H', 1), ('I', 1), ('J', 1), ('K', 1), ('L', 1), ('1', 1), ('2', 1), ('3', 1)])]\n"
     ]
    }
   ],
   "source": [
    "# extract_pdb_data('/Users/intermilan1102/Dropbox/All_paralogs/002_PDB_structures/1qso.pdb')\n",
    "print extract_pdb_data('~/Documents/Hiver2019/Paper_duplication/Submission_eLife_AC/Data/Interface_conservation/002_PDB_structures/1a1d.pdb', dict_text_2_numbers)\n",
    "print extract_pdb_data('~/Documents/Hiver2019/Paper_duplication/Submission_eLife_AC/Data/Interface_conservation/002_PDB_structures/2ja7.pdb', dict_text_2_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now let's just loop through all the structures to extract these data\n",
    "file_list = glob.glob('~/Documents/Hiver2019/Paper_duplication/Submission_eLife_AC/Data/Interface_conservation/002_PDB_structures/*pdb')\n",
    "handle_out = open('~/Documents/Hiver2019/Paper_duplication/Submission_eLife_AC/Data/Interface_conservation/003_data_tables/PDB_structures.txt', 'w')\n",
    "structure_dict = OrderedDict()\n",
    "\n",
    "## I decided I would not keep writing to a file. Instead, I will save all these data in a big dictionary\n",
    "# writer = csv.writer(handle_out, delimiter = '\\t')\n",
    "# header = ['PDB_ID', 'Biological_assembly', 'Number_of_subunits', 'Technique', 'Resolution']\n",
    "# writer.writerow(header)\n",
    "for pdb_file in file_list:\n",
    "    # print pdb_file\n",
    "    new_line = extract_pdb_data(pdb_file, dict_text_2_numbers)\n",
    "    \n",
    "    # The key will be the PDB ID and everything else will be in the values\n",
    "    structure_dict[new_line[0]] = new_line[1:6]\n",
    "#     writer.writerow(new_line)\n",
    "\n",
    "# handle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 15,\n",
       " 'X-RAY DIFFRACTION',\n",
       " '3.8',\n",
       " OrderedDict([('A', 1),\n",
       "              ('B', 1),\n",
       "              ('C', 1),\n",
       "              ('D', 1),\n",
       "              ('E', 1),\n",
       "              ('F', 1),\n",
       "              ('G', 1),\n",
       "              ('H', 1),\n",
       "              ('I', 1),\n",
       "              ('J', 1),\n",
       "              ('K', 1),\n",
       "              ('L', 1),\n",
       "              ('1', 1),\n",
       "              ('2', 1),\n",
       "              ('3', 1)])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure_dict['2ja7']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will just need to remember that empty dictionaries will mean that there is no information for transformations on chains in the PDB file. As such, I will just consider every chain to appear only once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data for the structures I could not download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the table with all the info about the structures\n",
    "handle_in = open('~/Documents/Hiver2019/Paper_duplication/Submission_eLife_AC/Data/Interface_conservation/003_data_tables/not_downloaded_reformatted.txt', 'r')\n",
    "reader = csv.reader(handle_in, delimiter = '\\t')\n",
    "\n",
    "for line in reader:\n",
    "    # I could also filter here based on the technique and the resolution if needed\n",
    "    # I can ask Rong what he thinks about this\n",
    "    \n",
    "    pdb_id = line[0]\n",
    "    bio_assembly = line[1]\n",
    "    subunit_num = line[2]\n",
    "    technique = line[3]\n",
    "    resolution = line[4]\n",
    "    comments = line[5]\n",
    "    \n",
    "    # Skip the first line\n",
    "    if pdb_id == 'PDB_ID':\n",
    "        continue\n",
    "    \n",
    "    # I will add all of this to the dictionary with the info on the downloaded structures\n",
    "    structure_dict[pdb_id] = [int(bio_assembly), int(subunit_num), technique, resolution, OrderedDict()]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 'X-RAY DIFFRACTION', '3.00', OrderedDict([('A', 2), ('B', 2)])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure_dict['1a3w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 15,\n",
       " 'X-RAY DIFFRACTION',\n",
       " '3.8',\n",
       " OrderedDict([('A', 1),\n",
       "              ('B', 1),\n",
       "              ('C', 1),\n",
       "              ('D', 1),\n",
       "              ('E', 1),\n",
       "              ('F', 1),\n",
       "              ('G', 1),\n",
       "              ('H', 1),\n",
       "              ('I', 1),\n",
       "              ('J', 1),\n",
       "              ('K', 1),\n",
       "              ('L', 1),\n",
       "              ('1', 1),\n",
       "              ('2', 1),\n",
       "              ('3', 1)])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I wanted to test this structure because YOR224C maps to chains H and T. These are on separate copies of the same\n",
    "# complex, so only one of them should count when looking at the biological assembly. I got this right because\n",
    "# assembly one only contains chain H, and so only chain H appears in this dictionary.\n",
    "structure_dict['2ja7']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the alignment data, I would like to have the following structure:\n",
    "- Main Dictionary\n",
    "    - First level: Dictionary with pairs of paralogs sorted alphabetically as keys\n",
    "        - Second level: Dictionary with P1 and P2 as keys\n",
    "            - Third level: Dictionaries with PDB IDs that were matched by P1 and P2, respectively, as keys\n",
    "                - Values: List of chains from each PDB ID that were matched by the respective paralog\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the alignment data as a dictionary\n",
    "alignment_dict = OrderedDict()\n",
    "handle_in = open('~/Documents/Hiver2019/Paper_duplication/Submission_eLife_AC/Data/Interface_conservation/003_data_tables/PDB_matches_all_chains_SSD_WGD.txt', 'r')\n",
    "reader = csv.reader(handle_in, delimiter = '\\t')\n",
    "\n",
    "unspecific_dict = OrderedDict()\n",
    "dup_type_dict = OrderedDict()\n",
    "\n",
    "for line in reader:\n",
    "    P1 = line[0]\n",
    "    P2 = line[14]\n",
    "    pair_list = [P1, P2]\n",
    "    pair_list.sort()\n",
    "    pair = tuple(pair_list)\n",
    "    \n",
    "    P1_match_PDB = line[1]\n",
    "    P1_match_chain = line[2]\n",
    "    \n",
    "    P1_unspecific = line[15]\n",
    "    P2_unspecific = line[16]\n",
    "    \n",
    "    dup_type = line[17]\n",
    "    \n",
    "    # Save the data about unspecific interactions and duplication types\n",
    "    unspecific_dict[P1] = P1_unspecific\n",
    "    unspecific_dict[P2] = P2_unspecific\n",
    "    \n",
    "    dup_type_dict[pair] = dup_type\n",
    "    \n",
    "    # Skip the first line\n",
    "    if P1 == 'P1':\n",
    "        continue\n",
    "    \n",
    "    # Now that I extracted all the info, I can start filling the dictionary\n",
    "    if alignment_dict.get(pair, -1) == -1:\n",
    "        # First level\n",
    "        alignment_dict[pair] = OrderedDict()\n",
    "        \n",
    "        # Second level\n",
    "        alignment_dict[pair][P1] = OrderedDict()\n",
    "        alignment_dict[pair][P2] = OrderedDict()\n",
    "        \n",
    "        # Third level\n",
    "        alignment_dict[pair][P1][P1_match_PDB] = [P1_match_chain]\n",
    "    \n",
    "    # Now, we can consider the case that the whole hierarchy is there but this is a new PDB structure\n",
    "    elif alignment_dict[pair][P1].get(P1_match_PDB, -1) == -1:\n",
    "        alignment_dict[pair][P1][P1_match_PDB] = [P1_match_chain]\n",
    "        \n",
    "    # Otherwise, everything is there and we just need to append to the list of matching chains\n",
    "    else:\n",
    "        alignment_dict[pair][P1][P1_match_PDB].append(P1_match_chain)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two examples of how the dictionary works. The first one shows the hierarchy and the second one shows how I have a list of four chains within the same structure that map to the same paralog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('YNL172W', 'YOR224C')\n",
      "YOR224C\n",
      "OrderedDict([('1a1d', ['A']), ('1i3q', ['H']), ('1i50', ['H']), ('1i6h', ['H']), ('1k83', ['H']), ('1nik', ['H']), ('1nt9', ['H']), ('1pqv', ['H']), ('1r5u', ['H']), ('1r9s', ['H']), ('1r9t', ['H']), ('1sfo', ['H']), ('1twa', ['H']), ('1twc', ['H']), ('1twf', ['H']), ('1twg', ['H']), ('1twh', ['H']), ('1wcm', ['H']), ('1y1v', ['H']), ('1y1w', ['H']), ('1y1y', ['H']), ('1y77', ['H']), ('2b63', ['H']), ('2b8k', ['H']), ('2e2h', ['H']), ('2e2i', ['H']), ('2e2j', ['H']), ('2ja5', ['H']), ('2ja6', ['H']), ('2ja7', ['H', 'T']), ('2ja8', ['H']), ('2nvq', ['H']), ('2nvt', ['H']), ('2nvx', ['H']), ('2nvy', ['H']), ('2nvz', ['H']), ('2r7z', ['H']), ('2r92', ['H']), ('2r93', ['H']), ('2vum', ['H']), ('2yu9', ['H']), ('3cqz', ['H']), ('3fki', ['H']), ('3gtg', ['H']), ('3gtj', ['H']), ('3gtk', ['H']), ('3gtl', ['H']), ('3gtm', ['H']), ('3gto', ['H']), ('3gtp', ['H']), ('3gtq', ['H']), ('3h3v', ['I']), ('3hou', ['H', 'T']), ('3hov', ['H']), ('3how', ['H']), ('3hox', ['H']), ('3hoy', ['H']), ('3hoz', ['H']), ('3i4m', ['H']), ('3i4n', ['H']), ('3j0k', ['H']), ('3j1n', ['H']), ('3k1f', ['H']), ('3k7a', ['H']), ('3m3y', ['H']), ('3m4o', ['H']), ('3po2', ['H']), ('3po3', ['H']), ('3qt1', ['H']), ('3rzd', ['H']), ('3rzo', ['H']), ('3s14', ['H']), ('3s15', ['H']), ('3s16', ['H']), ('3s17', ['H']), ('3s1m', ['H']), ('3s1n', ['H']), ('3s1q', ['H']), ('3s1r', ['H']), ('3s2d', ['H']), ('3s2h', ['H']), ('4a3b', ['H']), ('4a3c', ['H']), ('4a3d', ['H']), ('4a3e', ['H']), ('4a3f', ['H']), ('4a3g', ['H']), ('4a3i', ['H']), ('4a3j', ['H']), ('4a3k', ['H']), ('4a3l', ['H']), ('4a3m', ['H']), ('4a93', ['H']), ('4bbr', ['H']), ('4bbs', ['H']), ('4bxx', ['H']), ('4bxz', ['H']), ('4by1', ['H']), ('4c2m', ['H', 'W']), ('4c3h', ['H']), ('4c3i', ['H']), ('4c3j', ['H']), ('4v1m', ['H']), ('4v1n', ['H']), ('4v1o', ['H']), ('4x67', ['H']), ('4x6a', ['H']), ('4y52', ['H']), ('4y7n', ['H']), ('4ym7', ['AH', 'BH', 'CH', 'DH', 'EH', 'FH']), ('5c3e', ['H']), ('5c44', ['H']), ('5c4a', ['H']), ('5c4j', ['H']), ('5c4x', ['H']), ('5fj8', ['H']), ('5fj9', ['H']), ('5fja', ['H']), ('5fmf', ['H']), ('5fyw', ['H']), ('5fz5', ['H']), ('5g5l', ['H']), ('5ip7', ['H']), ('5ip9', ['H']), ('5lmx', ['H']), ('5m3f', ['H']), ('5m3m', ['H']), ('5m5w', ['H']), ('5m5x', ['H']), ('5m5y', ['H']), ('5m64', ['H']), ('5n5y', ['H']), ('5n5z', ['H']), ('5n60', ['H']), ('5n61', ['H']), ('5oa1', ['H']), ('5sva', ['H']), ('5u5q', ['H']), ('5w5y', ['H']), ('5w64', ['H']), ('5w65', ['H']), ('5w66', ['H'])])\n",
      "['A']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print alignment_dict.keys()[0]\n",
    "print alignment_dict[('YNL172W', 'YOR224C')].keys()[0]\n",
    "print alignment_dict[('YNL172W', 'YOR224C')]['YOR224C']\n",
    "print alignment_dict[('YNL172W', 'YOR224C')]['YOR224C']['1a1d']\n",
    "\n",
    "print alignment_dict[('YNL172W', 'YOR224C')]['YNL172W'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print alignment_dict[('YDR256C', 'YGR088W')]['YDR256C']['1a4e']\n",
    "print alignment_dict[('YDR256C', 'YGR088W')]['YGR088W'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is just an example of how the unspecific dict works\n",
    "unspecific_dict['YGR088W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SSD'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of the dictionary of the duplication types\n",
    "dup_type_dict[('YDR256C', 'YGR088W')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the final table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part should be a loop through the dictionaries that should allow me to look at each of the paralog pairs, then the structures that matched each of them, and the number of chains within each structure that mapped to them.\n",
    "\n",
    "I will also use the dictionaries on the structures' data and the unspecific interactions to complete the table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for this should be similar to what I used to have but checking if the chains I am considering\n",
    "are a part of the biological assembly the authors selected and how many times they appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "907"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(structure_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# handle_out = open('~/Documents/Hiver2019/Paper_duplication/Submission_eLife_AC/Data/Interface_conservation/003_data_tables/paralogs_PDB_structures.txt', 'w')\n",
    "handle_out = open('~/Documents/Hiver2019/Paper_duplication/Submission_eLife_AC/Data/Interface_conservation/003_data_tables/paralogs_PDB_structures_complete2.txt', 'w')\n",
    "writer = csv.writer(handle_out, delimiter = '\\t')\n",
    "header = ['P1_ID', 'P2_ID', 'Duplication_type','Monomer_P1', 'Monomer_P2', 'HM_P1', 'HM_P2', 'HET', 'other_HET_P1', 'other_HET_P2', 'P1_unspecific', 'P2_unspecific']\n",
    "writer.writerow(header)\n",
    "\n",
    "# Loop through the pairs of paralogs\n",
    "for pair in alignment_dict.keys():\n",
    "    P1 = pair[0]\n",
    "    P2 = pair[1]\n",
    "    \n",
    "    dup_type = dup_type_dict[pair]\n",
    "    P1_unspecific = unspecific_dict[P1]\n",
    "    P2_unspecific = unspecific_dict[P2]\n",
    "\n",
    "    monomers_P1_list = []\n",
    "    monomers_P2_list = []\n",
    "    HM_P1_list = []\n",
    "    HM_P2_list = []\n",
    "    other_HET_P1_list = []\n",
    "    other_HET_P2_list = []\n",
    "    HET_list = []\n",
    "    \n",
    "    # Let's work with P1 and the list of structures whose chains match it\n",
    "    for structure, chains in alignment_dict[pair][P1].items():\n",
    "        # I can check how many chains from that structure mapped to it\n",
    "        # To know the number of matches, I need to look at each of the chains that this paralog matched\n",
    "        # and how many times they appear in the biological assembly according to the structure dict.\n",
    "        \n",
    "        # Skip structures that were solved with solution NMR\n",
    "        if structure_dict[structure][2] == 'SOLUTION NMR':\n",
    "            continue\n",
    "        # However, I must remember that if the dictionary is empty, every chain is considered a part\n",
    "        # of the biological assembly. This is the case for some monomers and the big complexes.\n",
    "        elif len(structure_dict[structure][4].keys()) == 0:\n",
    "            matches_in_structure = len(chains)\n",
    "        else:\n",
    "            matches_in_structure = 0\n",
    "            for chain in chains:\n",
    "                # Let's see how many chains in the assembly derive from each of these matches\n",
    "                # If this chain is not in the assembly, count it as a zero\n",
    "                chain_matches = structure_dict[structure][4].get(chain, 0)\n",
    "                matches_in_structure = matches_in_structure + chain_matches\n",
    "        \n",
    "        # I can now check if this is a monomer (the assembly has only one chain AND there is one match)\n",
    "        if structure_dict[structure][1] == 1 and matches_in_structure == 1:\n",
    "            # I will save the monomer for P1 as the PDB_ID followed by an underscore and the number of the assembly\n",
    "            monomer_P1 = structure + '_' + str(structure_dict[structure][0])\n",
    "            monomers_P1_list.append(monomer_P1)\n",
    "        # or an HM (the assembly has more than one chain AND this paralog matches more than one chain)\n",
    "        elif structure_dict[structure][1] > 1 and matches_in_structure > 1:\n",
    "            HM_P1 = structure + '_' + str(structure_dict[structure][0])\n",
    "            HM_P1_list.append(HM_P1)\n",
    "        # or a HET but not of paralogs (other_HET)\n",
    "        elif structure_dict[structure][1] > 1 and matches_in_structure == 1:\n",
    "            other_HET_P1 = structure + '_' + str(structure_dict[structure][0])\n",
    "            other_HET_P1_list.append(other_HET_P1)\n",
    "    \n",
    "    # Let's work with P2 and the list of structures whose chains match it\n",
    "    for structure, chains in alignment_dict[pair][P2].items():\n",
    "        # I can check how many chains from that structure mapped to it\n",
    "        # To know the number of matches, I need to look at each of the chains that this paralog matched\n",
    "        # and how many times they appear in the biological assembly according to the structure dict.\n",
    "        \n",
    "        # Skip structures that were solved with solution NMR\n",
    "        if structure_dict[structure][2] == 'SOLUTION NMR':\n",
    "            continue\n",
    "        # However, I must remember that if the dictionary is empty, every chain is considered a part\n",
    "        # of the biological assembly. This is the case for some monomers and the big complexes.\n",
    "        elif len(structure_dict[structure][4].keys()) == 0:\n",
    "            matches_in_structure = len(chains)\n",
    "        else:\n",
    "            matches_in_structure = 0\n",
    "            for chain in chains:\n",
    "                # Let's see how many chains in the assembly derive from each of these matches\n",
    "                # If this chain is not in the assembly, count it as a zero\n",
    "                chain_matches = structure_dict[structure][4].get(chain, 0)\n",
    "                matches_in_structure = matches_in_structure + chain_matches\n",
    "            \n",
    "        # I can now check if this is a monomer (the assembly has only one chain AND there is only one match)\n",
    "        if structure_dict[structure][1] == 1 and matches_in_structure == 1:\n",
    "            # I will save the monomer for P2 as the PDB_ID followed by an underscore and the number of the assembly\n",
    "            monomer_P2 = structure + '_' + str(structure_dict[structure][0])\n",
    "            monomers_P2_list.append(monomer_P2)\n",
    "        # or an HM (the assembly has more than one chain AND this paralog matches more than one chain)\n",
    "        elif structure_dict[structure][1] > 1 and matches_in_structure > 1:\n",
    "            HM_P2 = structure + '_' + str(structure_dict[structure][0])\n",
    "            HM_P2_list.append(HM_P2)\n",
    "        # or a HET but not of paralogs (other_HET)\n",
    "        elif structure_dict[structure][1] > 1 and matches_in_structure == 1:\n",
    "            other_HET_P2 = structure + '_' + str(structure_dict[structure][0])\n",
    "            other_HET_P2_list.append(other_HET_P2)\n",
    "    \n",
    "    # Get the list of HET\n",
    "    # Start with the list of structures that have a match of P1 and P2\n",
    "    P1_matches = alignment_dict[pair][P1].keys()\n",
    "    P2_matches = alignment_dict[pair][P2].keys()\n",
    "    \n",
    "    # I can now loop through each of the structures in P1_matches and check if it also has matches for P2\n",
    "    for candidate in P1_matches:\n",
    "        if candidate in P2_matches:\n",
    "            chains_P1 = alignment_dict[pair][P1][candidate]\n",
    "            chains_P2 = alignment_dict[pair][P2][candidate]\n",
    "            total_chains = structure_dict[candidate][1]\n",
    "            assembly = structure_dict[candidate][0]\n",
    "            \n",
    "            chains_P1_match = 0\n",
    "            if len(structure_dict[candidate][4].keys()) == 0:\n",
    "                chains_P1_match = len(chains_P1)\n",
    "            else:\n",
    "                for chain in chains_P1:\n",
    "                    P1_chain_matches = structure_dict[candidate][4].get(chain, 0)\n",
    "                    chains_P1_match = chains_P1_match + P1_chain_matches \n",
    "\n",
    "            chains_P2_match = 0\n",
    "            if len(structure_dict[candidate][4].keys()) == 0:\n",
    "                chains_P2_match = len(chains_P2)\n",
    "            else:\n",
    "                for chain in chains_P2:\n",
    "                    P2_chain_matches = structure_dict[candidate][4].get(chain, 0)\n",
    "                    chains_P2_match = chains_P2_match + P2_chain_matches             \n",
    "            \n",
    "            # Then, I just have to check if:\n",
    "            # There is at least one match for P1 AND \n",
    "            # There is at least one match for P2 AND\n",
    "            # The assembly has at least as many subunits as the sum of matches of P1 and P2\n",
    "            if chains_P1_match >= 1 and chains_P2_match >= 1 and total_chains >= (chains_P1_match + chains_P2_match):\n",
    "                HET = candidate + '_' + str(assembly)\n",
    "                HET_list.append(HET)\n",
    "                # I will remove them from the lists of other HET if they are there\n",
    "                if HET in other_HET_P1_list:\n",
    "                    other_HET_P1_list.remove(HET)\n",
    "                if HET in other_HET_P2_list:\n",
    "                    other_HET_P2_list.remove(HET)\n",
    "    \n",
    "    # Once I have all of this, I can just join all the elements from each of the lists and put everything together to\n",
    "    # write the line. If the lists are empty, I will write NA instead\n",
    "    save_bool = False\n",
    "    if len(monomers_P1_list) == 0:\n",
    "        monomers_P1 = 'NA'\n",
    "    else:\n",
    "        monomers_P1 = ','.join(monomers_P1_list)\n",
    "        save_bool = True\n",
    "        \n",
    "    if len(monomers_P2_list) == 0:\n",
    "        monomers_P2 = 'NA'\n",
    "    else:    \n",
    "        monomers_P2 = ','.join(monomers_P2_list)\n",
    "        save_bool = True\n",
    "        \n",
    "    if len(HM_P1_list) == 0:\n",
    "        HM_P1 = 'NA'\n",
    "    else:\n",
    "        HM_P1 = ','.join(HM_P1_list)\n",
    "        save_bool = True\n",
    "        \n",
    "    if len(HM_P2_list) == 0:\n",
    "        HM_P2 = 'NA'\n",
    "    else:\n",
    "        HM_P2 = ','.join(HM_P2_list)\n",
    "        save_bool = True\n",
    "        \n",
    "    if len(HET_list) == 0:\n",
    "        HET = 'NA'\n",
    "    else:\n",
    "        HET = ','.join(HET_list)\n",
    "        save_bool = True\n",
    "        \n",
    "    if len(other_HET_P1_list) == 0:\n",
    "        other_HET_P1 = 'NA'\n",
    "    else:\n",
    "        other_HET_P1 = ','.join(other_HET_P1_list)\n",
    "        save_bool = True\n",
    "        \n",
    "    if len(other_HET_P2_list) == 0:\n",
    "        other_HET_P2 = 'NA'\n",
    "    else:\n",
    "        other_HET_P2 = ','.join(other_HET_P2_list)\n",
    "        save_bool = True\n",
    "        \n",
    "    # Now, I can put everything together and write the new row\n",
    "    if save_bool == True:\n",
    "        new_row = [P1, P2, dup_type, monomers_P1, monomers_P2, HM_P1, HM_P2, HET, other_HET_P1, other_HET_P2, P1_unspecific, P2_unspecific]\n",
    "        writer.writerow(new_row)\n",
    "\n",
    "handle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YJL105W',\n",
       " 'YKR029C',\n",
       " 'WGD',\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'NA',\n",
       " '5tdr_1,5tdw_1',\n",
       " '0',\n",
       " '0']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict()\n",
      "OrderedDict([('5tdr', ['A']), ('5tdw', ['A'])])\n",
      "[1, 2, 'X-RAY DIFFRACTION', '1.42', OrderedDict([('A', 1), ('B', 1)])]\n",
      "[1, 2, 'X-RAY DIFFRACTION', '1.70', OrderedDict([('A', 1), ('B', 1)])]\n"
     ]
    }
   ],
   "source": [
    "# I will do some tests to see if this is working properly.\n",
    "# The final pair of paralogs has no monomers, HM, or HET. The only match I could find was for YKR029C as part of\n",
    "# a dimeric complex with a protein that is not YJL105W.\n",
    "print alignment_dict[('YJL105W', 'YKR029C')]['YJL105W']\n",
    "print alignment_dict[('YJL105W', 'YKR029C')]['YKR029C']\n",
    "print structure_dict['5tdr']\n",
    "print structure_dict['5tdw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict()\n",
      "OrderedDict([('5c2y', ['A', 'B'])])\n",
      "[1, 1, 'X-RAY DIFFRACTION', '2.60', OrderedDict([('A', 1)])]\n"
     ]
    }
   ],
   "source": [
    "# Let's test: YDR066C YER139C WGD     NA      5c2y_1  NA      NA      NA      0       1\n",
    "# This is correctly assigned as a monomer for YER139C\n",
    "print alignment_dict[('YDR066C', 'YER139C')]['YDR066C']\n",
    "print alignment_dict[('YDR066C', 'YER139C')]['YER139C']\n",
    "print structure_dict['5c2y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict()\n",
      "OrderedDict([('3l4n', ['A']), ('5j3r', ['A'])])\n",
      "[1, 1, 'X-RAY DIFFRACTION', '1.50', OrderedDict([('A', 1)])]\n",
      "[1, 2, 'X-RAY DIFFRACTION', '2.46', OrderedDict([('A', 2)])]\n"
     ]
    }
   ],
   "source": [
    "# Let's test: YBR014C YDL010W WGD     NA      3l4n_1  NA      5j3r_1  NA      0       0\n",
    "# These are correctly assigned as a monomeric structure and a homodimer\n",
    "print alignment_dict[('YBR014C', 'YDL010W')]['YBR014C']\n",
    "print alignment_dict[('YBR014C', 'YDL010W')]['YDL010W']\n",
    "print structure_dict['3l4n']\n",
    "print structure_dict['5j3r']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's write some code to check which of the HMs are strict homomers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, I will just need to look at the entries in the final table and check their subunits with the structure and alignment dictionaries I loaded previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the final data table\n",
    "handle = open('~/Documents/Hiver2019/Paper_duplication/Submission_eLife_AC/Data/Interface_conservation/003_data_tables/paralogs_PDB_structures_complete2.txt', 'r')\n",
    "table_reader = csv.reader(handle, delimiter = '\\t')\n",
    "\n",
    "# Skip headers\n",
    "header = table_reader.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the block I originally used to look for strict homomers in the pairs that had no HET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for line in table_reader:\n",
    "    \n",
    "    # I am especially interested in pairs that have two HM but no HET. Are they strict HMs or occurrences of more\n",
    "    # than one copy in bigger complexes?\n",
    "    paralog_1 = line[0]\n",
    "    paralog_2 = line[1]\n",
    "    HM_1 = line[5]\n",
    "    HM_2 = line[6]\n",
    "    HET = line[7]\n",
    "    \n",
    "    if HM_1 != 'NA' and HM_2 != 'NA' and HET == 'NA':\n",
    "        # print line\n",
    "        \n",
    "        HM_1 = HM_1.split(',')\n",
    "        HM_2 = HM_2.split(',')\n",
    "        \n",
    "        print 'Checking', paralog_1, 'and', paralog_2\n",
    "        \n",
    "        # Then, I should look at each of the structures in HM_1 and HM_2 and their chains based on the\n",
    "        # alignment and structure dictionaries.\n",
    "        for structure in HM_1:\n",
    "            # Check which chains in that structure correspond to paralog 1\n",
    "            chains = alignment_dict[(paralog_1, paralog_2)][paralog_1][structure[0:4]]\n",
    "            # I can get the total number of chains that come from those chains\n",
    "            total = 0\n",
    "            \n",
    "            print structure\n",
    "            \n",
    "            for chain in chains:\n",
    "                # Get the total number of times this chain appears in the biological assembly\n",
    "                # Some might not appear because they could be present in the file but in a different assembly\n",
    "                chain_appears = structure_dict[structure[0:4]][4].get(chain,0)\n",
    "                \n",
    "                # Count the total number of chains\n",
    "                total = total + chain_appears\n",
    "            \n",
    "            # Check if it is a strict HM. This would be the case if all the chains that form the structure were matches\n",
    "            if total == structure_dict[structure[0:4]][1]:\n",
    "                print structure, 'is a strict HM for', paralog_1\n",
    "            \n",
    "        # Repeat for HM_2\n",
    "        for structure in HM_2:\n",
    "            # Check which chains in that structure correspond to paralog 1\n",
    "            chains = alignment_dict[(paralog_1, paralog_2)][paralog_2][structure[0:4]]\n",
    "            # I can get the total number of chains that come from those chains\n",
    "            total = 0\n",
    "            \n",
    "            print structure\n",
    "            \n",
    "            for chain in chains:\n",
    "                # Get the total number of times this chain appears in the biological assembly\n",
    "                # Some might not appear because they could be present in the file but in a different assembly\n",
    "                chain_appears = structure_dict[structure[0:4]][4].get(chain, 0)\n",
    "                \n",
    "                # Count the total number of chains\n",
    "                total = total + chain_appears \n",
    "                \n",
    "            # Check if it is a strict HM. This would be the case if all the chains that form the structure were matches\n",
    "            if total == structure_dict[structure[0:4]][1]:\n",
    "                print structure, 'is a strict HM for', paralog_2\n",
    "        \n",
    "        print '------'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the blocks I used to fill the table with info on the strict homomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the final data table\n",
    "handle = open('~/Documents/Hiver2019/Paper_duplication/Submission_eLife_AC/Data/Interface_conservation/003_data_tables/paralogs_PDB_structures_complete2.txt', 'r')\n",
    "table_reader = csv.reader(handle, delimiter = '\\t')\n",
    "\n",
    "# Skip headers\n",
    "header = table_reader.next()\n",
    "\n",
    "# Prepare the file to write\n",
    "handle_writer = open('~/Documents/Hiver2019/Paper_duplication/Submission_eLife_AC/Data/Interface_conservation/003_data_tables/paralogs_PDB_structures_with_strict2.txt', 'w')\n",
    "writer = csv.writer(handle_writer, delimiter = '\\t')\n",
    "\n",
    "header = ['P1_ID', 'P2_ID', 'Duplication_type','Monomer_P1', 'Monomer_P2', 'HM_P1', 'HM_P2', 'HET', 'other_HET_P1', 'other_HET_P2', 'P1_unspecific', 'P2_unspecific', 'Strict_HM_P1', 'Strict_HM_P2']   \n",
    "writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in table_reader:\n",
    "    \n",
    "    # Are they strict HMs or occurrences of more\n",
    "    # than one copy in bigger complexes?\n",
    "    paralog_1 = line[0]\n",
    "    paralog_2 = line[1]\n",
    "    HM_1 = line[5]\n",
    "    HM_2 = line[6]\n",
    "    HET = line[7]\n",
    "    strict_HM_1 = []\n",
    "    strict_HM_2 = []\n",
    "    \n",
    "    HM_1 = HM_1.split(',')\n",
    "    HM_2 = HM_2.split(',')\n",
    "\n",
    "    # I just need to make sure that these paralogs are not matched to NAs\n",
    "    if HM_1[0] == 'NA':\n",
    "        # No HMs means there are no strict HMs\n",
    "        line.append('NA')\n",
    "    else:\n",
    "        # Then, I should look at each of the structures in HM_1 and HM_2 and their chains based on the\n",
    "        # alignment and structure dictionaries.\n",
    "        for structure in HM_1:\n",
    "            # Check which chains in that structure correspond to paralog 1\n",
    "            chains = alignment_dict[(paralog_1, paralog_2)][paralog_1][structure[0:4]]\n",
    "            # I can get the total number of chains that come from those chains\n",
    "            total = 0\n",
    "\n",
    "            for chain in chains:\n",
    "                # Get the total number of times this chain appears in the biological assembly\n",
    "                # Some might not appear because they could be present in the file but in a different assembly\n",
    "                chain_appears = structure_dict[structure[0:4]][4].get(chain,0)\n",
    "\n",
    "                # Count the total number of chains\n",
    "                total = total + chain_appears\n",
    "\n",
    "            # Check if it is a strict HM. This would be the case if all the chains that form the structure were matches\n",
    "            if total == structure_dict[structure[0:4]][1]:\n",
    "                # Then we have a strict HM for paralog 1\n",
    "                strict_HM_1.append(structure)\n",
    "        \n",
    "        # Now, we should just add the data on strict homomers to the line and write to a file\n",
    "        # If there are strict homomers we write them to the column. Otherwise, we write NA.\n",
    "        if len(strict_HM_1) > 0:\n",
    "            strict_HM_1_final = ','.join(strict_HM_1)\n",
    "            line.append(strict_HM_1_final)\n",
    "        else:\n",
    "            line.append('NA')\n",
    "\n",
    "    # Repeat for HM_2\n",
    "    # I just need to make sure that these paralogs are not matched to NAs\n",
    "    if HM_2[0] == 'NA':\n",
    "        # No HMs means there are no strict HMs\n",
    "        line.append('NA')\n",
    "    else:\n",
    "        for structure in HM_2:\n",
    "            # Check which chains in that structure correspond to paralog 1\n",
    "            chains = alignment_dict[(paralog_1, paralog_2)][paralog_2][structure[0:4]]\n",
    "            # I can get the total number of chains that come from those chains\n",
    "            total = 0\n",
    "\n",
    "            for chain in chains:\n",
    "                # Get the total number of times this chain appears in the biological assembly\n",
    "                # Some might not appear because they could be present in the file but in a different assembly\n",
    "                chain_appears = structure_dict[structure[0:4]][4].get(chain, 0)\n",
    "\n",
    "                # Count the total number of chains\n",
    "                total = total + chain_appears \n",
    "\n",
    "            # Check if it is a strict HM. This would be the case if all the chains that form the structure were matches\n",
    "            if total == structure_dict[structure[0:4]][1]:\n",
    "                # Then we have a strict HM for paralog 2\n",
    "                strict_HM_2.append(structure)\n",
    "\n",
    "        if len(strict_HM_2) > 0:\n",
    "            strict_HM_2_final = ','.join(strict_HM_2)\n",
    "            line.append(strict_HM_2_final)\n",
    "        else:\n",
    "            line.append('NA')\n",
    "    \n",
    "    writer.writerow(line)\n",
    "\n",
    "handle_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1']\n"
     ]
    }
   ],
   "source": [
    "a = '1'\n",
    "b = a.split('a')\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 'X-RAY DIFFRACTION', '2.00', OrderedDict([('A', 1), ('C', 1)])]\n",
      "['A', 'B', 'C']\n"
     ]
    }
   ],
   "source": [
    "print structure_dict['3w4y']\n",
    "print alignment_dict['YGR029W','YPR037C']['YGR029W']['3w4y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('YML007W', OrderedDict([('1sse', ['A', 'B'])])), ('YDR423C', OrderedDict())])\n",
      "[1, 1, 'SOLUTION NMR', 'NA', OrderedDict()]\n"
     ]
    }
   ],
   "source": [
    "print alignment_dict[('YDR423C', 'YML007W')]\n",
    "print structure_dict['1sse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('YDR409W', OrderedDict([('2rnn', ['A'])])), ('YOR156C', OrderedDict())])\n",
      "[1, 1, 'SOLUTION NMR', 'NA', OrderedDict()]\n"
     ]
    }
   ],
   "source": [
    "print alignment_dict[('YDR409W', 'YOR156C')]\n",
    "print structure_dict['2rnn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use a loop to select the complexes with the best resolution for interface analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "handle = open('~/Documents/Hiver2019/Paper_duplication/Submission_eLife_AC/Data/Interface_conservation/003_data_tables/paralogs_PDB_structures_with_strict2.txt', 'r')\n",
    "reader = csv.reader(handle, delimiter = '\\t')\n",
    "\n",
    "handle_writer = open('~/Documents/Hiver2019/Paper_duplication/Submission_eLife_AC/Data/Interface_conservation/003_data_tables/paralogs_PDB_structures_best_structures2.txt', 'w')\n",
    "writer = csv.writer(handle_writer, delimiter = '\\t')\n",
    "\n",
    "header = ['P1_ID', 'P2_ID', 'Duplication_type', 'HM_P1', 'HM_P2', 'HET', 'P1_unspecific', 'P2_unspecific', 'Strict_HM_P1', 'Strict_HM_P2']   \n",
    "writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Skip the first line\n",
    "header = reader.next()\n",
    "\n",
    "for line in reader:\n",
    "    P1_ID = line[0]\n",
    "    P2_ID = line[1]\n",
    "    dup_type = line[2]\n",
    "    \n",
    "    HM_P1 = line[5]\n",
    "    best_HM_P1 = ['NA', 1000]\n",
    "    \n",
    "    HM_P2 = line[6]\n",
    "    best_HM_P2 = ['NA', 1000]\n",
    "    \n",
    "    HET = line[7]\n",
    "    best_HET = ['NA', 1000]\n",
    "    \n",
    "    P1_unspecific = line[10]\n",
    "    P2_unspecific = line[11]\n",
    "    \n",
    "    strict_HM_P1 = line[12]\n",
    "    best_strict_HM_P1 = ['NA', 1000]\n",
    "    \n",
    "    strict_HM_P2 = line[13]\n",
    "    best_strict_HM_P2 = ['NA', 1000]\n",
    "    \n",
    "    bool_save = False\n",
    "    \n",
    "    # We have to look at the list of structures in each column, and select the crystal with the best resolution\n",
    "    if HM_P1 != 'NA':\n",
    "        for structure in HM_P1.split(','):\n",
    "            # Get the resolution of such structure if it is a crystal\n",
    "            structure_info = structure_dict[structure[0:4]]\n",
    "            technique = structure_info[2]\n",
    "            resolution = float(structure_info[3])\n",
    "            if technique == 'X-RAY DIFFRACTION' and resolution < best_HM_P1[1]:\n",
    "                best_HM_P1 = [structure, resolution]\n",
    "                bool_save = True\n",
    "    \n",
    "    \n",
    "    if HM_P2 != 'NA':\n",
    "        for structure in HM_P2.split(','):\n",
    "            # Get the resolution of such structure if it is a crystal\n",
    "            structure_info = structure_dict[structure[0:4]]\n",
    "            technique = structure_info[2]\n",
    "            resolution = float(structure_info[3])\n",
    "            if technique == 'X-RAY DIFFRACTION' and resolution < best_HM_P2[1]:\n",
    "                best_HM_P2 = [structure, resolution]\n",
    "                bool_save = True\n",
    "                \n",
    "    if HET != 'NA':\n",
    "        for structure in HET.split(','):\n",
    "            # Get the resolution of such structure if it is a crystal\n",
    "            structure_info = structure_dict[structure[0:4]]\n",
    "            technique = structure_info[2]\n",
    "            resolution = float(structure_info[3])\n",
    "            if technique == 'X-RAY DIFFRACTION' and resolution < best_HET[1]:\n",
    "                best_HET = [structure, resolution]\n",
    "                bool_save = True\n",
    "            \n",
    "    if strict_HM_P1 != 'NA':\n",
    "        for structure in strict_HM_P1.split(','):\n",
    "            # Get the resolution of such structure if it is a crystal\n",
    "            structure_info = structure_dict[structure[0:4]]\n",
    "            technique = structure_info[2]\n",
    "            resolution = float(structure_info[3])\n",
    "            if technique == 'X-RAY DIFFRACTION' and resolution < best_strict_HM_P1[1]:\n",
    "                best_strict_HM_P1 = [structure, resolution]\n",
    "                bool_save = True\n",
    "            \n",
    "    if strict_HM_P2 != 'NA':\n",
    "        for structure in strict_HM_P2.split(','):\n",
    "            # Get the resolution of such structure if it is a crystal\n",
    "            structure_info = structure_dict[structure[0:4]]\n",
    "            technique = structure_info[2]\n",
    "            resolution = float(structure_info[3])\n",
    "            if technique == 'X-RAY DIFFRACTION' and resolution < best_strict_HM_P2[1]:\n",
    "                best_strict_HM_P2 = [structure, resolution]\n",
    "                bool_save = True\n",
    "                \n",
    "    # Now that we have all of them, we can just write the info to the table\n",
    "    if bool_save:\n",
    "        new_row = [P1_ID, P2_ID, dup_type, best_HM_P1[0], best_HM_P2[0], best_HET[0], P1_unspecific, P2_unspecific, best_strict_HM_P1[0], best_strict_HM_P2[0]]\n",
    "        writer.writerow(new_row)\n",
    "        \n",
    "handle_writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
